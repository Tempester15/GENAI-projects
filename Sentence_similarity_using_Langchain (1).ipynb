{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "yK3inVNniMqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "66e9ccaa-b3c0-42cd-eea7-254ada594568"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community sentence-transformers -q"
      ],
      "metadata": {
        "id": "QmeDcY2lL7lD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dd1c81ab-4b75-4e44-e374-bf843b8ebd95"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YYYAYYRxMFlU",
        "outputId": "1f6186ee-f143-4c96-f1c9-42c3d1d180ab"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
        "from pdfminer.high_level import extract_text\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import paired_euclidean_distances\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "vAOMydNCmMlw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1cad8f04-223f-4933-d945-dcdde4d45d81"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qz65YYhZ8gxc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1_text = extract_text(\"doc1.pdf\")\n",
        "doc2_text = extract_text(\"doc2.pdf\")\n",
        "doc3_text = extract_text(\"doc3.pdf\")"
      ],
      "metadata": {
        "id": "cyg3wIV1o-lS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b68f1487-412d-4cc8-d3a3-cccfa87b6ce0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc1_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VOk5baXEAGHR",
        "outputId": "dc5c47d5-093f-43bb-d6ef-a38eb6b73e1d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large language models, also known as LLMs, are very large deep\n",
            "learning models that are pre-trained on vast amounts of data. The\n",
            "underlying transformer is a set of neural networks that consist of an\n",
            "encoder and a decoder with self-attention capabilities. The encoder and\n",
            "decoder extract meanings from a sequence of text and understand the\n",
            "relationships between words and phrases in it.\n",
            "\n",
            "Transformer LLMs are capable of unsupervised training, although a more\n",
            "precise explanation is that\n",
            "is\n",
            "through this process that transformers learn to understand basic grammar,\n",
            "languages, and knowledge.\n",
            "\n",
            "transformers perform self-learning. It\n",
            "\n",
            "Unlike earlier recurrent neural networks (RNN) that sequentially process\n",
            "inputs, transformers process entire sequences in parallel. This allows the\n",
            "data scientists to use GPUs for\n",
            "training transformer-based LLMs,\n",
            "significantly reducing the training time.\n",
            "\n",
            "arge language models are incredibly flexible. One model can perform\n",
            "completely different tasks such as answering questions, summarizing\n",
            "documents, translating languages and completing sentences. LLMs have\n",
            "the potential to disrupt content creation and the way people use search\n",
            "engines and virtual assistants.\n",
            "\n",
            "While not perfect, LLMs are demonstrating a remarkable ability to make\n",
            "predictions based on a relatively small number of prompts or inputs.\n",
            "LLMs can be used for generative AI (artificial intelligence) to produce\n",
            "content based on input prompts in human language.\n",
            "\n",
            "LLMs are big, very big. They can consider billions of parameters and\n",
            "have many possible uses. Here are some examples:\n",
            "\n",
            "Open AI's GPT-3 model has 175 billion parameters. Its cousin, ChatGPT,\n",
            "can identify patterns from data and generate natural and readable output.\n",
            "While we don’t know the size of Claude 2, it can take inputs up to 100K\n",
            "tokens in each prompt, which means it can work over hundreds of pages\n",
            "of technical documentation or even an entire book.\n",
            "AI21 Labs’ Jurassic-1 model has 178 billion parameters and a token\n",
            "vocabulary of 250,000-word parts and similar conversational capabilities.\n",
            "Cohere’s Command model has similar capabilities and can work in more\n",
            "than 100 different languages.\n",
            "LightOn's Paradigm offers foundation models with claimed capabilities\n",
            "that exceed those of GPT-3. All these LLMs come with APIs that allow\n",
            "developers to create unique generative AI applications.\n",
            "\n",
            "\fName : Amey Kelkar\n",
            "Address : AB - 406, Signature residency, Kolar road, Bhopal, 462042.\n",
            "\n",
            "How do large language models work?\n",
            "A key factor in how LLMs work is the way they represent words. Earlier\n",
            "forms of machine learning used a numerical table to represent each word.\n",
            "But, this form of representation could not recognize relationships between\n",
            "words such as words with similar meanings. This limitation was\n",
            "overcome by using multi-dimensional vectors, commonly referred to as\n",
            "to represent words so that words with similar\n",
            "word embeddings,\n",
            "contextual meanings or other relationships are close to each other in the\n",
            "vector space.\n",
            "\n",
            "Using word embeddings, transformers can pre-process text as numerical\n",
            "representations through the encoder and understand the context of words\n",
            "and phrases with similar meanings as well as other relationships between\n",
            "words such as parts of speech. It is then possible for LLMs to apply this\n",
            "knowledge of the language through the decoder to produce a unique\n",
            "output.\n",
            "\n",
            "What are applications of large language models?\n",
            "There are many practical applications for LLMs.\n",
            "\n",
            "Copywriting\n",
            "Apart from GPT-3 and ChatGPT, Claude, Llama 2, Cohere Command,\n",
            "and Jurassiccan write original copy. AI21 Wordspice suggests changes to\n",
            "original sentences to improve style and voice.\n",
            "\n",
            "Knowledge base answering\n",
            "Often referred to as knowledge-intensive natural language processing\n",
            "(KI-NLP),\n",
            "the technique refers to LLMs that can answer specific\n",
            "questions from information help in digital archives. An example is the\n",
            "ability of AI21 Studio playground to answer general knowledge questions.\n",
            "\n",
            "Text classification\n",
            "Using clustering, LLMs can classify text with similar meanings or\n",
            "sentiments. Uses include measuring customer sentiment, determining the\n",
            "relationship between texts, and document search.\n",
            "\n",
            "Code generation\n",
            "LLM are proficient in code generation from natural language prompts.\n",
            "Amazon Q Developer can code in Python, JavaScript, Ruby and several\n",
            "\n",
            "\fother programming languages. Other coding applications include creating\n",
            "SQL queries, writing shell commands and website design.\n",
            "\n",
            "Text generation\n",
            "Similar to code generation, text generation can complete incomplete\n",
            "sentences, write product documentation or, like Alexa Create, write a\n",
            "short children's story.\n",
            "\n",
            "How are large language models trained?\n",
            "Transformer-based neural networks are very large. These networks\n",
            "contain multiple nodes and layers. Each node in a layer has connections\n",
            "to all nodes in the subsequent layer, each of which has a weight and a bias.\n",
            "Weights and biases along with embeddings are known as model\n",
            "parameters. Large transformer-based neural networks can have billions\n",
            "and billions of parameters. The size of the model is generally determined\n",
            "by an empirical relationship between the model size, the number of\n",
            "parameters, and the size of the training data.\n",
            "\n",
            "Training is performed using a large corpus of high-quality data. During\n",
            "training, the model iteratively adjusts parameter values until the model\n",
            "correctly predicts the next token from an the previous squence of input\n",
            "tokens. It does this through self-learning techniques which teach the\n",
            "model to adjust parameters to maximize the likelihood of the next tokens\n",
            "in the training examples.\n",
            "\n",
            "Once trained, LLMs can be readily adapted to perform multiple tasks\n",
            "using relatively small sets of supervised data, a process known as fine\n",
            "tuning.\n",
            "\n",
            "Three common learning models exist:\n",
            "\n",
            "Zero-shot learning; Base LLMs can respond to a broad range of requests\n",
            "without explicit\n",
            "training, often through prompts, although answer\n",
            "accuracy varies.\n",
            "Few-shot learning: By providing a few relevant training examples, base\n",
            "model performance significantly improves in that specific area.\n",
            "Fine-tuning: This is an extension of few-shot\n",
            "learning in that data\n",
            "scientists train a base model to adjust its parameters with additional data\n",
            "relevant to the specific application.\n",
            "What is the future of LLMs?\n",
            "The introduction of large language models like ChatGPT, Claude 2, and\n",
            "Llama 2 that can answer questions and generate text points to exciting\n",
            "possibilities in the future. Slowly, but surely, LLMs are moving closer to\n",
            "\n",
            "\fthese LLMs\n",
            "human-like performance. The immediate success of\n",
            "demonstrates a keen interest in robotic-type LLMs that emulate and, in\n",
            "some contexts, outperform the human brain. Here are some thoughts on\n",
            "the future of LLMs,\n",
            "\n",
            "Increased capabilities\n",
            "As impressive as they are, the current level of technology is not perfect\n",
            "and LLMs are not infallible. However, newer releases will have improved\n",
            "accuracy and enhanced capabilities as developers learn how to improve\n",
            "their performance while reducing bias and eliminating incorrect answers.\n",
            "\n",
            "Audiovisual training\n",
            "While developers train most LLMs using text, some have started training\n",
            "models using video and audio input. This form of training should lead to\n",
            "faster model development and open up new possibilities in terms of using\n",
            "LLMs for autonomous vehicles.\n",
            "\n",
            "Workplace transformation\n",
            "LLMs are a disruptive factor that will change the workplace. LLMs will\n",
            "likely reduce monotonous and repetitive tasks in the same way that robots\n",
            "did for repetitive manufacturing tasks. Possibilities include repetitive\n",
            "service chatbots, and simple automated\n",
            "clerical\n",
            "copywriting.\n",
            "\n",
            "tasks, customer\n",
            "\n",
            "Conversational AI\n",
            "LLMs will undoubtedly improve the performance of automated virtual\n",
            "assistants like Alexa, Google Assistant, and Siri. They will be better able\n",
            "to interpret user intent and respond to sophisticated commands.\n",
            "\n",
            "How can AWS help with LLMs?\n",
            "AWS offers several possibilities for large language model developers.\n",
            "Amazon Bedrock is the easiest way to build and scale generative AI\n",
            "applications with LLMs. Amazon Bedrock is a fully managed service that\n",
            "makes LLMs from Amazon and leading AI startups available through an\n",
            "API, so you can choose from various LLMs to find the model that's best\n",
            "suited for your use case.\n",
            "\n",
            "Amazon SageMaker JumpStart is a machine learning hub with foundation\n",
            "models, built-in algorithms, and prebuilt ML solutions that you can\n",
            "deploy with just a few clicks With SageMaker JumpStart, you can access\n",
            "pretrained models, including foundation models, to perform tasks like\n",
            "article summarization and image generation. Pretrained models are fully\n",
            "\n",
            "\fcustomizable for your use case with your data, and you can easily deploy\n",
            "them into production with the user interface or SDK.\n",
            "\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc2_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ib6TV0r_AKwS",
        "outputId": "27b8c58b-9c96-4173-82e6-d8366a97b35c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name : Amey Kelkar\n",
            "Address : AB - 406, Signature residency, Kolar road, Bhopal, 462042.\n",
            "\n",
            "LangChain is a framework for developing applications powered by large\n",
            "language models (LLMs).\n",
            "\n",
            "LangChain simplifies every stage of the LLM application lifecycle:\n",
            "\n",
            "blocks,\n",
            "\n",
            "third-party\n",
            "\n",
            "components,\n",
            "\n",
            "Development: Build your applications using LangChain's open-source\n",
            "integrations. Use\n",
            "and\n",
            "building\n",
            "LangGraph to build stateful agents with first-class streaming and human-\n",
            "in-the-loop support.\n",
            "Productionization: Use LangSmith to inspect, monitor and evaluate your\n",
            "chains, so that you can continuously optimize and deploy with confidence.\n",
            "Deployment: Turn your LangGraph applications into production-ready\n",
            "APIs and Assistants with LangGraph Cloud.\n",
            "\n",
            "Concretely, the framework consists of the following open-source libraries:\n",
            "\n",
            "langchain-core: Base abstractions and LangChain Expression Language.\n",
            "langchain-community: Third party integrations.\n",
            "Partner packages (e.g. langchain-openai, langchain-anthropic, etc.): Some\n",
            "integrations have been further split into their own lightweight packages\n",
            "that only depend on langchain-core.\n",
            "langchain: Chains, agents, and retrieval strategies that make up an\n",
            "application's cognitive architecture.\n",
            "LangGraph: Build robust and stateful multi-actor applications with LLMs\n",
            "by modeling steps as edges and nodes in a graph. Integrates smoothly\n",
            "with LangChain, but can be used without it.\n",
            "LangServe: Deploy LangChain chains as REST APIs.\n",
            "LangSmith: A developer platform that lets you debug, test, evaluate, and\n",
            "monitor LLM applications.\n",
            "\n",
            "At LangChain’s core is a development environment that streamlines the\n",
            "programming of LLM applications through the use of abstraction: the\n",
            "simplification of code by representing one or more complex processes as\n",
            "a named component that encapsulates all of its constituent steps.\n",
            "\n",
            "Abstractions are a common element of everyday life and language. For\n",
            "example, “π” allows us to represent the ratio of the length of a circle’s\n",
            "circumference to that of its diameter without having to write out its\n",
            "infinite digits. Similarly, a thermostat allows us to control the temperature\n",
            "in our home without needing to understand the complex circuitry this\n",
            "\n",
            "\fentails—we only need to know how different thermostat settings translate\n",
            "to different temperatures.\n",
            "\n",
            "LangChain is essentially a library of abstractions for Python and\n",
            "Javascript, representing common steps and concepts necessary to work\n",
            "with language models. These modular components—like functions and\n",
            "object classes—serve as the building blocks of generative AI programs.\n",
            "They can be “chained” together to create applications, minimizing the\n",
            "amount of code and fine understanding required to execute complex NLP\n",
            "tasks. Though LangChain’s abstracted approach may limit the extent to\n",
            "which an expert programmer can finely customize an application, it\n",
            "empowers specialists and newcomers alike to quickly experiment and\n",
            "prototype.\n",
            "\n",
            "Importing language models\n",
            "Nearly any LLM can be used in LangChain. Importing language models\n",
            "into LangChain is easy, provided you have an API key. The LLM class is\n",
            "designed to provide a standard interface for all models.\n",
            "\n",
            "Most LLM providers will require you to create an account in order to\n",
            "these APIs—particularly those for\n",
            "receive an API key. Some of\n",
            "like those offered by OpenAI or\n",
            "proprietary closed-source models,\n",
            "Anthropic—may have associated costs.\n",
            "\n",
            "Many open source models,\n",
            "like BigScience’s BLOOM, Meta AI’s\n",
            "LLaMa and Google’s Flan-T5, can be accessed through Hugging Face\n",
            "(link resides outside ibm.com). IBM watsonx, through its partnership\n",
            "with Hugging Face, also offers a curated suite of open source models.\n",
            "Creating an account with either service will allow you to generate an API\n",
            "key for any of the models offered by that provider.\n",
            "\n",
            "limited to out-of-the-box foundation models:\n",
            "\n",
            "the\n",
            "LangChain is not\n",
            "CustomLLM class (link resides outside ibm.com) allows for custom LLM\n",
            "wrappers. Likewise, you can use the IBM watsonx APIs and Python SDK,\n",
            "to build applications in\n",
            "which includes a LangChain integration,\n",
            "LangChain with models that you’ve already trained or fine-tuned for your\n",
            "specific needs using the WatsonxLLM class (and that model’s specific\n",
            "project ID).\n",
            "\n",
            "Applications made with LangChain provide great utility for a variety of\n",
            "use cases, from straightforward question-answering and text generation\n",
            "tasks to more complex solutions that use an LLM as a “reasoning engine.”\n",
            "\n",
            "\fintuitive uses of LLMs.\n",
            "Chatbots: Chatbots are among the most\n",
            "LangChain can be used to provide proper context for the specific use of a\n",
            "chatbot, and to integrate chatbots into existing communication channels\n",
            "and workflows with their own APIs.\n",
            "Summarization: Language models can be tasked with summarizing many\n",
            "types of text, from breaking down complex academic articles and\n",
            "transcripts to providing a digest of incoming emails.\n",
            "Question answering: Using specific documents or specialized knowledge\n",
            "bases (like Wolfram, arXiv or PubMed), LLMs can retrieve relevant\n",
            "information from storage and articulate helpful answers). If fine-tuned or\n",
            "properly prompted, some LLMs can answer many questions even without\n",
            "external information.\n",
            "Data augmentation: LLMs can be used to generate synthetic data for use\n",
            "in machine learning. For example, an LLM can be trained to generate\n",
            "additional data samples that closely resemble the data points in a training\n",
            "dataset.\n",
            "Virtual agents: Integrated with the right workflows, LangChain’s Agent\n",
            "modules can use an LLM to autonomously determine next steps and take\n",
            "action using robotic process automation (RPA).\n",
            "\n",
            "Large Language Models (LLMs) have revolutionized Natural Language\n",
            "Processing (NLP), serving as essential components in a wide range of\n",
            "applications, such as question-answering, summarization, translation, and\n",
            "text generation.\n",
            "\n",
            "The adoption of LLMs is creating a new tech stack in its wake. However,\n",
            "emerging libraries and tools are predominantly being developed for the\n",
            "Python and JavaScript ecosystems. As a result,\n",
            "the number of\n",
            "ecosystems has grown\n",
            "applications\n",
            "exponentially.\n",
            "\n",
            "leveraging LLMs\n",
            "\n",
            "in these\n",
            "\n",
            "In contrast, the Dart / Flutter ecosystem has not experienced similar\n",
            "growth, which can likely be attributed to the scarcity of Dart and Flutter\n",
            "libraries that streamline the complexities associated with working with\n",
            "LLMs.\n",
            "\n",
            "LangChain.dart aims to fill this gap by abstracting the intricacies of\n",
            "working with LLMs in Dart and Flutter, enabling developers to harness\n",
            "their combined potential effectively.\n",
            "\n",
            "\fWhere LangChain excels\n",
            "For applications like chatbots and automated customer support, where\n",
            "retaining the context of a conversation is crucial for providing relevant\n",
            "responses.\n",
            "Prompting LLMs to execute tasks like generating text,\n",
            "languages, or answering queries.\n",
            "loaders that provide access to various documents from\n",
            "Document\n",
            "different sources and formats, enhancing the LLM's ability to draw from\n",
            "a rich knowledge base.\n",
            "LangChain uses text embedding models to create embeddings that\n",
            "capture the semantic meaning of texts, improving content discovery and\n",
            "retrieval. It supports over 50 different storage options for embeddings,\n",
            "storage, and retrieval.\n",
            "\n",
            "translating\n",
            "\n",
            "Context Retention\n",
            "LlamaIndex is primarily designed for search and retrieval tasks. While it\n",
            "offers basic context\n",
            "is not optimized for\n",
            "managing long interactions. It excels in quick and efficient retrieval of\n",
            "relevant information, making it ideal for applications focused on fast data\n",
            "access and simple search tasks.\n",
            "\n",
            "retention capabilities,\n",
            "\n",
            "it\n",
            "\n",
            "LangChain, on the other hand, provides advanced context retention\n",
            "features. It can maintain context over extended interactions, making it\n",
            "require longer and more complex\n",
            "suitable for applications\n",
            "retrieval\n",
            "such as\n",
            "conversations,\n",
            "algorithms with language models, which allows\n",
            "to generate\n",
            "contextually relevant\n",
            "responses by retaining and utilizing previous\n",
            "interactions throughout the conversation.\n",
            "\n",
            "that\n",
            "chatbots. LangChain integrates\n",
            "\n",
            "it\n",
            "\n",
            "While LangChain and LlamaIndex offer great tools for data management\n",
            "and AI integration, it's important to consider the databases behind the\n",
            "scenes. MyScale is a cloud-based SQL vector database that combines the\n",
            "features of traditional SQL databases and vector databases. This makes it\n",
            "perfect for handling structured data, like tables and lists, and unstructured\n",
            "data, like images and text.\n",
            "\n",
            "What is MyScale\n",
            "\n",
            "MyScale performs fast and accurate searches using advanced AI\n",
            "techniques while still being easy to use with regular SQL commands. You\n",
            "get the best of both worlds: powerful data processing and simple, familiar\n",
            "tools. By using MyScale with LangChain or LlamaIndex, developers can\n",
            "\n",
            "\fcreate more efficient and scalable applications. Additionally, MyScale is\n",
            "designed to handle large amounts of data, making it a great choice for\n",
            "building smart, AI-driven systems.\n",
            "\n",
            "LangChain is a Python library that serves as a bridge between large\n",
            "language models and real-world applications. It aims to simplify the\n",
            "integration of LLMs into various workflows, enabling developers to\n",
            "harness their immense potential easily.At its core, LangChain provides a\n",
            "modular and composable framework that allows developers to build\n",
            "sophisticated applications by combining different components, such as\n",
            "language models, data sources, and processing steps. This modular\n",
            "approach promotes code reusability, facilitates rapid prototyping, and\n",
            "streamlines the development process, enabling teams to focus on\n",
            "delivering innovative solutions rather than grappling with complex\n",
            "integrations.\n",
            "\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc3_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-JPwTJZ3AOpE",
        "outputId": "604de4d4-85b3-44a7-e5ff-7b8cd975bcfb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torrey Canyon oil spill\n",
            "\n",
            "The Torrey Canyon oil spill was one of the world's most serious oil spills.\n",
            "The supertanker SS Torrey Canyon ran aground on rocks off the south-\n",
            "west coast of the United Kingdom in 1967, spilling an estimated 25–36\n",
            "million gallons (94–164 million litres) of crude oil.[1] Attempts to\n",
            "mitigate the damage included the bombing of the wreck by aircraft from\n",
            "the Royal Navy and Royal Air Force. Hundreds of miles of coastline in\n",
            "Britain, France, Guernsey, and Spain were affected by the oil and other\n",
            "substances used to mitigate damage.[2] It was the world's worst oil spill\n",
            "and led to significant changes in maritime law and oil spill responses.\n",
            "\n",
            "Background\n",
            "Main article: SS Torrey Canyon\n",
            "When laid down in the United States in 1959, Torrey Canyon had a\n",
            "capacity of 60,000 tons; the ship was later enlarged to 120,000 tons in\n",
            "Japan. [3] She was named for a geographical feature in California. Torrey\n",
            "Canyon was registered in Liberia and owned by Barracuda Tanker\n",
            "Corporation, a subsidiary of Union Oil Company of California but\n",
            "chartered to British Petroleum.[4] She was 974.4 ft (297.0 m) long, 125.4\n",
            "ft (38.2 m) beam and 68.7 ft (20.9 m) draught.\n",
            "\n",
            "Accident\n",
            "On her final voyage, Torrey Canyon left the Kuwait National Petroleum\n",
            "Company refinery at Mina Al-Ahmadi, Kuwait (later Al-Ahmadi), with a\n",
            "full cargo of crude oil, on 19 February 1967. The ship had an intended\n",
            "destination of Milford Haven in Wales. On 14 March, she reached the\n",
            "Canary Islands. Following a navigational error, Torrey Canyon struck\n",
            "Pollard's Rock on the extreme Western end of the Seven Stones between\n",
            "the Cornish mainland and the Isles of Scilly on 18 March 1967.\n",
            "\n",
            "The tanker did not have a scheduled route and so lacked a complement of\n",
            "full-scale charts of the Scilly Islands. When a collision with a fishing fleet\n",
            "became imminent, there was some confusion between the Master and the\n",
            "officer of the watch as to their exact position. Significant further delay\n",
            "arose due to uncertainty as to whether the vessel was in manual or\n",
            "automatic steering mode, with the Master mistakenly believing he had\n",
            "switched the steering to manual for the helmsman. By the time the\n",
            "problem was corrected, a grounding was unavoidable. In the hours and\n",
            "days to follow, extensive attempts to float the vessel off the reef failed\n",
            "and even resulted in the death of a member of the Dutch salvage team,\n",
            "Captain Hans Barend Stal.\n",
            "\n",
            "\fAfter the attempts to move the vessel failed and the ship began to break\n",
            "up, the focus became the clean up and containment of the resulting oil\n",
            "spill. Huge amounts of detergent was used by Cornwall fire brigade and\n",
            "attending Royal Navy vessels to try to disperse the oil. UK Prime\n",
            "Minister Harold Wilson and his cabinet held a mini cabinet meeting at the\n",
            "Royal Naval Air Station Culdrose and decided to set fire to the vessel and\n",
            "surrounding oil slick to limit the extent of the oil disaster.\n",
            "\n",
            "On 28 March 1967, the Fleet Air Arm sent Blackburn Buccaneer planes\n",
            "from RNAS Lossiemouth to drop forty-two 1,000 lb (450 kg) bombs on\n",
            "the ship. Then, the Royal Air Force sent Hawker Hunter jets from RAF\n",
            "Chivenor to drop cans of aviation fuel\n",
            "to make the oil blaze.[5]\n",
            "Exceptionally high tides put the fire out and it took further bombing runs\n",
            "by Sea Vixens from the RNAS Yeovilton and Buccaneers from the Royal\n",
            "Navy Air Station Brawdy, as well as more RAF Hunters with liquefied\n",
            "petroleum jelly (napalm) to ignite the oil. Bombing continued into the\n",
            "next day before Torrey Canyon finally sank.[6] About 161 1,000 lb (450\n",
            "kg) bombs, 11,000 imp gal (50,000 L; 13,000 US gal) of kerosene, 3,000\n",
            "imp gal (14,000 L; 3,600 US gal) of napalm and 16 other missiles had\n",
            "been aimed at\n",
            "the ship.[7] Attempts to use foam-filled containment\n",
            "booms were mostly ineffectual because of the high seas.\n",
            "\n",
            "Environmental impact\n",
            "About 50 miles (80 km) of French and 120 miles (190 km) of Cornish\n",
            "coast were contaminated. Around 15,000 sea birds were killed, along\n",
            "with huge numbers of marine organisms, before the 270 square miles\n",
            "(700 km2) slick dispersed. Much damage was caused by the heavy use of\n",
            "so-called detergents to break up the slick – these were first-generation\n",
            "variants of products originally formulated to clean surfaces in ships'\n",
            "engine-rooms, with no concern over the toxicity of their components.\n",
            "Many observers[who?] believed that they were officially referred to as\n",
            "to\n",
            "'detergents',\n",
            "encourage comparison with much more benign domestic cleaning\n",
            "products.\n",
            "\n",
            "than the more accurate 'solvent-emulsifiers',\n",
            "\n",
            "rather\n",
            "\n",
            "Some 42 vessels sprayed over 10,000 tons of these dispersants onto the\n",
            "floating oil and they were also deployed against oil stranded on beaches.\n",
            "In Cornwall, they were often misused – for example, by emptying entire\n",
            "45-gallon drums over the clifftop to 'treat' inaccessible coves or by\n",
            "pouring a steady stream from a low-hovering helicopter. On the heavily\n",
            "oiled beach at Sennen Cove, dispersant pouring from drums was\n",
            "'ploughed' into the sand by bulldozers over a period of several days,\n",
            "\n",
            "\fburying the oil so effectively that it could still be found a year or more\n",
            "later.\n",
            "\n",
            "Some of the oil from the ship was dumped in a quarry on the Chouet\n",
            "headland on Guernsey in the Channel Islands, where it remains. Efforts to\n",
            "rid the island of the oil have continued, with limited success.[2][8]\n",
            "\n",
            "Aftermath\n",
            "The British government was strongly criticised for its handling of the\n",
            "incident, which was at that time the costliest shipping disaster ever. The\n",
            "RAF and the Royal Navy were also subject to ridicule as a result of their\n",
            "efforts to assist in resolving the matter, given that as many as 25% of the\n",
            "42 bombs that they dropped missed the enormous stationary target.[9]\n",
            "\n",
            "The British and French governments made claims against the owners of\n",
            "the vessel; the subsequent settlement was the largest ever in marine\n",
            "history for an oil claim.[10] In traditional maritime law, ships can sue and\n",
            "be sued, but their liability is limited to the value of the ship and its cargo.\n",
            "its value was that of one\n",
            "After the Torrey Canyon was wrecked,\n",
            "remaining lifeboat worth $50, some 1⁄160,000 of the damages.[11]\n",
            "Liberian law did not provide for direct liability of the ship's owners. The\n",
            "British government was able to serve a writ against the ship's owners only\n",
            "by arresting the Torrey Canyon's sister ship, the Lake Palourde, when she\n",
            "put in for provisions at Singapore, four months after the oil spill. A young\n",
            "British lawyer, Anthony O'Connor, from a Singaporean law firm, Drew &\n",
            "Napier, was deputised to arrest\n",
            "the ship on behalf of the British\n",
            "government by attaching a writ to its mast. O'Connor was able to board\n",
            "the ship and serve the writ because the ship's crew thought he was a\n",
            "whisky salesman. The French government, alerted to the Lake Palourde's\n",
            "presence, pursued the ship with motor boats, but crew were unable to\n",
            "board and serve their writ.[12]\n",
            "\n",
            "The disaster led to many changes in international regulations, such as the\n",
            "International Convention on Civil Liability for Oil Pollution Damage\n",
            "(CLC) of 1969, which imposed strict liability on ship owners without the\n",
            "need to prove negligence, and the 1973 International Convention for the\n",
            "Prevention of Pollution from Ships.[13]\n",
            "\n",
            "An inquiry in Liberia, where the ship was registered, found that the\n",
            "Shipmaster, Pastrengo Rugiati, was to blame for having made a bad\n",
            "decision in steering Torrey Canyon between the Scillies and the Seven\n",
            "Stones. The first officer made ill-advised course corrections while the\n",
            "\n",
            "\fcaptain slept. Safer course alternatives were discarded because of the\n",
            "pressure to arrive in port at Milford Haven by high tide on 18 March.[14]\n",
            "\n",
            "The problems of reducing death following \"immersion hypothermia\"\n",
            "which were highlighted by the disaster led to \"development of new\n",
            "techniques for safety and rescue at sea\" and changes in the way survivors\n",
            "are winched from the sea.[15]\n",
            "\n",
            "Two flaws have also been noted in the design of the steering control:\n",
            "\n",
            "The steering lever was designed to switch the steering to a \"Control\n",
            "mode\", intended for use in maintenance only, which disconnected the\n",
            "rudder from the steering wheel.\n",
            "The design of the steering selector unit did not provide an indication of\n",
            "the peculiar mode at the helm.[16][17][18]\n",
            "The wreck is now largely broken up and is scattered over a wide area.[19]\n",
            "\n",
            "In popular culture\n",
            "Botanist David Bellamy came to public prominence as an environmental\n",
            "consultant during the disaster. He made his first prominent TV\n",
            "appearances after publishing a report on the episode.[20] He went on to\n",
            "be a leading environmental and nature campaigner for decades.\n",
            "\n",
            "In 1967 French singer Serge Gainsbourg wrote a song named \"Torrey\n",
            "Canyon\" about the disaster.\n",
            "\n",
            "Professor Martin Attrill, director of the Marine Institute in Plymouth, said\n",
            "the British response to the crisis illustrates how different attitudes to the\n",
            "environment were then.\n",
            "\n",
            "\"At the time the Torrey Canyon went down we were still considering the\n",
            "sea as the main place to put all our waste,\" he said.\n",
            "\n",
            "\"We've had a change in mindset. At the time it was 'the environment can\n",
            "deal with this' and the main concern was for the ship and whether it could\n",
            "be salvaged.\n",
            "\n",
            "\"Then people started to wake up - not just to the environment, but to the\n",
            "fact it reduced tourism. People didn't want to visit areas where there'd\n",
            "been an oil spill, there was an inability to sell goods, the brand was\n",
            "tarnished. Now we know about the benefits of clean seas.\"\n",
            "\n",
            "\fOn the affected section of the Breton coast, breeding pairs had returned\n",
            "from their migration to nest when the disaster happened. The Ligue pour\n",
            "la Protection des Oiseaux , externalcalculated that there were 450 pairs of\n",
            "razorbills before the spill but only 50 after. For guillemots the number of\n",
            "pairs fell from 270 to 50.\n",
            "\n",
            "About 85% of puffins on the French coast were also killed, the RSPB\n",
            "estimated. Because of their low reproductive rate, it took several decades\n",
            "for the population to recover.\n",
            "Name : Amey Kelkar\n",
            "Address : AB - 406, Signature residency, Kolar road, Bhopal, 462042.\n",
            "\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(doc, query):\n",
        "  vec = TfidfVectorizer()\n",
        "  vec_doc = vec.fit_transform(doc)\n",
        "  vec_query = vec.transform([query])\n",
        "  similarity = cosine_similarity(vec_query, vec_doc)\n",
        "  index = similarity.argmax()\n",
        "  print(f\"retrieved document :  {doc[index]}\\n index : {index}\")\n",
        "  print(f\"similarity score : {similarity[0][index] * 100}\")\n",
        "\n",
        "  return doc[index]\n",
        "\n",
        "def simple_preprocess(text):\n",
        "  lm = WordNetLemmatizer()\n",
        "  sentences = sent_tokenize(text)\n",
        "  preprocessed = []\n",
        "  for i in range(len(sentences)):\n",
        "    x = re.sub(\"[^a-zA-Z0-9]\", \" \", sentences[i])\n",
        "    x = x.lower().split()\n",
        "    x = [lm.lemmatize(word) for word in x if word not in set(stopwords.words(\"english\"))]\n",
        "    x = \" \".join(x)\n",
        "    preprocessed.append(x)\n",
        "\n",
        "  return preprocessed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zJv3bLmqoLsC",
        "outputId": "70e8cc90-3505-4c61-b9b9-ec8e208ac1cd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_doc1 = simple_preprocess(doc1_text)\n",
        "preprocessed_doc2 = simple_preprocess(doc2_text)\n",
        "preprocessed_doc3 = simple_preprocess(doc3_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Xv09xUt3o6tl",
        "outputId": "22eb0215-0350-420e-d314-fa220c021493"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'name address'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-0LvvSH3wLRv",
        "outputId": "ee10d2b1-79f3-49a8-9f5f-c925b118c96d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1_r = retrieve(preprocessed_doc1, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "8os--OEKtmAj",
        "outputId": "d76b14d4-2d5f-4fa5-97ce-0407a30dcef3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retrieved document :  name amey kelkar address ab 406 signature residency kolar road bhopal 462042\n",
            " index : 21\n",
            "similarity score : 40.824829046386306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2_r = retrieve(preprocessed_doc2, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "gCebE87vttbx",
        "outputId": "1f7aeed5-b59e-467c-e64f-03dae1dd7e81"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retrieved document :  name amey kelkar address ab 406 signature residency kolar road bhopal 462042\n",
            " index : 0\n",
            "similarity score : 40.824829046386306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3_r = retrieve(preprocessed_doc3, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "0DtR9Q9Etu8L",
        "outputId": "3bf42ce8-a048-4841-b0ea-5f63427872a2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retrieved document :  name amey kelkar address ab 406 signature residency kolar road bhopal 462042\n",
            " index : 71\n",
            "similarity score : 40.824829046386306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(sentence1, sentence2):\n",
        "    # Convert sentences to sets of words\n",
        "    set1 = set(sentence1.lower().split())\n",
        "    set2 = set(sentence2.lower().split())\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "\n",
        "    # Return Jaccard similarity\n",
        "    return (len(intersection) / len(union)) * 100 if len(union) > 0 else 0\n",
        "\n",
        "# Two sentences\n",
        "sentence1 = \"Python is a programming language.\"\n",
        "sentence2 = \"Python is widely used for programming.\"\n",
        "\n",
        "# Calculate Jaccard similarity\n",
        "similarity_score = jaccard_similarity(sentence1, sentence2)\n",
        "print(f\"Jaccard Similarity: {similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lH53LSMfwZsh",
        "outputId": "7a8f4080-8dde-4828-b8a1-00091954af05"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity: 22.22222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def cosine_similar_sent(sent1, sent2):\n",
        "  vec = TfidfVectorizer()\n",
        "  mat = vec.fit_transform([sent1, sent2])\n",
        "  similarity = cosine_similarity(mat[0:1], mat[1:2])\n",
        "  return similarity[0][0] * 100\n",
        "\n",
        "def euclid_dis(sent1, sent2):\n",
        "  vec = TfidfVectorizer()\n",
        "  mat = vec.fit_transform([sent1, sent2])\n",
        "  similarity = paired_euclidean_distances(mat[0:1], mat[1:2])\n",
        "  return similarity[0]\n",
        "\n",
        "\n",
        "def jaccard_similarity(sentence1, sentence2):\n",
        "    set1 = set(sentence1.lower().split())\n",
        "    set2 = set(sentence2.lower().split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "\n",
        "    return (len(intersection) / len(union)) * 100 if len(union) > 0 else 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pQhc6aUI2rHM",
        "outputId": "e67e39cd-eda0-45f1-90a4-915ec6db18b5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score1 = [jaccard_similarity(doc1_r, doc2_r), jaccard_similarity(doc1_r, doc3_r)]\n",
        "score2 = [cosine_similar_sent(doc1_r, doc2_r), cosine_similar_sent(doc1_r, doc3_r)]\n",
        "score3 = [euclid_dis(doc1_r, doc2_r), euclid_dis(doc1_r, doc3_r)]\n",
        "score2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pTC6GYnN4-sh",
        "outputId": "33fda399-9ef8-4461-b97c-af7f25a06d31"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100.00000000000003, 100.00000000000003]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = pd.DataFrame(\n",
        "    columns = ['doc1_to_doc2', 'doc1_to_doc3'],\n",
        "    data = [score1, score2, score3],\n",
        "    index = ['jaccard similarity', 'cosine similarity', 'euclidean distance']\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "b1KTGAm15rK5",
        "outputId": "79b32552-94ae-47fe-a02b-a855de71afb7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "iHhXkScI7erg",
        "outputId": "c97c6815-7cbc-40fa-9baa-14a2864daae9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    doc1_to_doc2  doc1_to_doc3\n",
              "jaccard similarity         100.0         100.0\n",
              "cosine similarity          100.0         100.0\n",
              "euclidean distance           0.0           0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-466dc447-2ac4-4aff-82da-e1848cb757a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc1_to_doc2</th>\n",
              "      <th>doc1_to_doc3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>jaccard similarity</th>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cosine similarity</th>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>euclidean distance</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-466dc447-2ac4-4aff-82da-e1848cb757a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-466dc447-2ac4-4aff-82da-e1848cb757a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-466dc447-2ac4-4aff-82da-e1848cb757a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fdfae2ff-73a5-4bda-8af6-5e0f331020d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdfae2ff-73a5-4bda-8af6-5e0f331020d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fdfae2ff-73a5-4bda-8af6-5e0f331020d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_00ead3b8-e77f-4d31-967e-87434618457b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('scores')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_00ead3b8-e77f-4d31-967e-87434618457b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('scores');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "scores",
              "summary": "{\n  \"name\": \"scores\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"doc1_to_doc2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57.73502691896259,\n        \"min\": 0.0,\n        \"max\": 100.00000000000003,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          100.0,\n          100.00000000000003,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc1_to_doc3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57.73502691896259,\n        \"min\": 0.0,\n        \"max\": 100.00000000000003,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          100.0,\n          100.00000000000003,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H62JbgBB7miO"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}